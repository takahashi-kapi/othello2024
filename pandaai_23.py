BLACK=1
WHITE=2

board = [
        [0,0,0,0,0,0],
        [0,0,0,0,0,0],
        [0,0,1,2,0,0],
        [0,0,2,1,0,0],
        [0,0,0,0,0,0],
        [0,0,0,0,0,0],
]


class AI(object):

    def face(self):
        return "ğŸ¼"

    def place(self, board, stone):
        return x, y


import random
import math

BLACK = 1
WHITE = 2

# ã‚ªã‚»ãƒ­ã®ãƒœãƒ¼ãƒ‰
board = [
    [0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0],
    [0, 0, 1, 2, 0, 0],
    [0, 0, 2, 1, 0, 0],
    [0, 0, 0, 0, 0, 0],
    [0, 0, 0, 0, 0, 0],
]

# Q-learningã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
ALPHA = 0.1  # å­¦ç¿’ç‡
GAMMA = 0.9  # å‰²å¼•ç‡
EPSILON = 0.2  # æ¢ç´¢ç‡ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã«å‹•ãç¢ºç‡ï¼‰
Q_TABLE = {}  # Qãƒ†ãƒ¼ãƒ–ãƒ« (çŠ¶æ…‹ -> è¡Œå‹•ã®Qå€¤)

def can_place_x_y(board, stone, x, y):
    if board[y][x] != 0:
        return False
    opponent = 3 - stone
    directions = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]
    for dx, dy in directions:
        nx, ny = x + dx, y + dy
        found_opponent = False
        while 0 <= nx < len(board[0]) and 0 <= ny < len(board) and board[ny][nx] == opponent:
            nx += dx
            ny += dy
            found_opponent = True
        if found_opponent and 0 <= nx < len(board[0]) and 0 <= ny < len(board) and board[ny][nx] == stone:
            return True
    return False

def can_place(board, stone):
    for y in range(len(board)):
        for x in range(len(board[0])):
            if can_place_x_y(board, stone, x, y):
                return True
    return False

def random_place(board, stone):
    while True:
        x = random.randint(0, len(board[0]) - 1)
        y = random.randint(0, len(board) - 1)
        if can_place_x_y(board, stone, x, y):
            return x, y

def get_state(board):
    """ãƒœãƒ¼ãƒ‰ã®çŠ¶æ…‹ã‚’ã‚¿ãƒ—ãƒ«ã«å¤‰æ›ã—ã¦è¿”ã™"""
    return tuple(tuple(row) for row in board)

def update_q_table(state, action, reward, next_state):
    """Qãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ›´æ–°ã™ã‚‹"""
    if state not in Q_TABLE:
        Q_TABLE[state] = {}
    if action not in Q_TABLE[state]:
        Q_TABLE[state][action] = 0

    # æ¬¡ã®çŠ¶æ…‹ã®æœ€å¤§Qå€¤
    next_max_q = max(Q_TABLE.get(next_state, {}).values(), default=0)

    # Qå€¤ã®æ›´æ–°
    Q_TABLE[state][action] += ALPHA * (reward + GAMMA * next_max_q - Q_TABLE[state][action])

def choose_action(board, stone):
    """è¡Œå‹•ã‚’é¸æŠã™ã‚‹"""
    state = get_state(board)

    # æ¢ç´¢ã¨æ´»ç”¨ã®ãƒãƒ©ãƒ³ã‚¹
    if random.random() < EPSILON:
        # ãƒ©ãƒ³ãƒ€ãƒ ã«è¡Œå‹•
        return random_place(board, stone)
    else:
        # Qãƒ†ãƒ¼ãƒ–ãƒ«ã«åŸºã¥ãæœ€é©è¡Œå‹•
        if state not in Q_TABLE:
            Q_TABLE[state] = {}

        best_action = None
        best_q_value = -math.inf

        for y in range(len(board)):
            for x in range(len(board[0])):
                if can_place_x_y(board, stone, x, y):
                    if (x, y) not in Q_TABLE[state]:
                        Q_TABLE[state][(x, y)] = 0  # åˆæœŸåŒ–
                    q_value = Q_TABLE[state][(x, y)]
                    if q_value > best_q_value:
                        best_q_value = q_value
                        best_action = (x, y)

        return best_action

class PandaAI(object):
    def face(self):
        return "ğŸ¼"

    def place(self, board, stone):
        # æœ€é©ãªæ‰‹ã‚’é¸ã¶
        return choose_action(board, stone)

def play_game():
    """ã‚²ãƒ¼ãƒ ã‚’1å›å®Ÿè¡Œã—ã¦å­¦ç¿’ã™ã‚‹"""
    board_copy = [row[:] for row in board]  # ãƒœãƒ¼ãƒ‰ã®ã‚³ãƒ”ãƒ¼
    turn = BLACK  # æœ€åˆã¯é»’ãŒå…ˆæ‰‹
    while can_place(board_copy, turn):
        x, y = PandaAI().place(board_copy, turn)
        board_copy[y][x] = turn
        turn = 3 - turn  # é»’ã¨ç™½ã‚’äº¤äº’ã«

    # ã‚²ãƒ¼ãƒ çµ‚äº†å¾Œã«å ±é…¬ã‚’æ›´æ–°
    return board_copy

# ã‚²ãƒ¼ãƒ ã®å®Ÿè¡Œä¾‹ï¼ˆæ•°å›ç¹°ã‚Šè¿”ã™ï¼‰
for _ in range(1000):  # 1000å›å¯¾æˆ¦
    final_board = play_game()
    winner = 1  # ã“ã“ã§ã¯ç°¡å˜ã«é»’ã®å‹ã¡ã¨ã™ã‚‹
    if winner == 1:
        reward = 1  # é»’ãŒå‹ã£ãŸå ´åˆ
    else:
        reward = -1  # ç™½ãŒå‹ã£ãŸå ´åˆ

    # ã‚²ãƒ¼ãƒ ã®çŠ¶æ…‹ã¨å ±é…¬ã«åŸºã¥ã„ã¦Qãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ›´æ–°
    state = get_state(final_board)
    for action in Q_TABLE.get(state, {}):
        update_q_table(state, action, reward, state)

!pip install -U kogi-canvas

from kogi_canvas import play_othello, PandaAI

BLACK=1
WHITE=2

board = [
        [0,0,0,0,0,0],
        [0,0,0,0,0,0],
        [0,0,1,2,0,0],
        [0,0,2,1,0,0],
        [0,0,0,0,0,0],
        [0,0,0,0,0,0],
]

play_othello(NonAI()) # ã“ã“ã‚’è‡ªåˆ†ã®ä½œã£ãŸAIã«å¤‰ãˆã‚‹
